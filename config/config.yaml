env: 
  ticker: ETH-USD
  interval: 1h
  period: 1y
  train_prop: 0.7
  window_size: 30
  indicators: [RSI]                      # [MOM, MACD, MFI, RSI, ATR, CO, OBV]
a2c: 
  policy: "MlpPolicy"
  policy_kwargs:
    net_arch: 
      vf: [128, 128, 128]
      pi: [64, 64]
  learning_rate: .0007
  n_steps: 5
  gamma: 0.99
  verbose: 1
ppo: 
  policy: "MlpPolicy"
  policy_kwargs:
    net_arch: 
      vf: [128, 128, 128]
      pi: [64, 64]
  batch_size: 64
  learning_rate: .0007
  n_steps: 4
  gamma: 0.99
  n_epochs: 5
  clip_range: .2
  verbose: 0
optim: 
  n_episodes: 10
  max_no_improvement_evals: 3
  min_evals: 5                        # must be <= n_episodes
  save_path: models/ppo_eth_1y/       # name containing model type and env args